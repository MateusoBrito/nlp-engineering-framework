classic_models:
  knn:
    n_neighbors: [3, 5, 7, 11]
    metric: ['euclidean', 'manhattan']

  svm:
    C: [0.1, 1, 10]
    kernel: ['linear', 'rbf']

  dt:
    criterion: ['gini', 'entropy']
    max_depth: [null, 5, 10, 20]

transformer_models:
  neuralmind/bert-base-portuguese-cased:
    learning_rate: 2e-5
    num_train_epochs: 3
    per_device_train_batch_size: 16
    weight_decay: 0.01
    logging_steps: 10
    
  google-bert/bert-base-uncased:
    learning_rate: 3e-5
    num_train_epochs: 4
    per_device_train_batch_size: 8